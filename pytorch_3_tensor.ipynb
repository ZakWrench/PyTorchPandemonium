{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6a9f2067",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Fatihi\\.conda\\envs\\Pytorch_1\\lib\\site-packages\\tqdm\\auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a291b8ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1, 2],\n",
      "        [3, 4]])\n",
      "tensor([[1, 2],\n",
      "        [3, 4]], dtype=torch.int32)\n",
      "\n",
      "Ones Tensor: \n",
      "tensor([[1, 1],\n",
      "        [1, 1]]) \n",
      "Random Tensor: \n",
      "tensor([[0.0503, 0.1256],\n",
      "        [0.3595, 0.2704]]) \n",
      "\n",
      "Random Tensor: \n",
      "tensor([[0.0363, 0.2474, 0.4729],\n",
      "        [0.7089, 0.9606, 0.5128]]) \n",
      "Ones Tensor: \n",
      "tensor([[1., 1., 1.],\n",
      "        [1., 1., 1.]]) \n",
      "Zeros Tensor: \n",
      "tensor([[0., 0., 0.],\n",
      "        [0., 0., 0.]])\n"
     ]
    }
   ],
   "source": [
    "# Initializing from data\n",
    "data = [[1,2],[3,4]]\n",
    "x_data = torch.tensor(data)\n",
    "print(x_data)\n",
    "\n",
    "# From a NumPy Array\n",
    "np_array = np.array(data)\n",
    "x_np = torch.from_numpy(np_array)\n",
    "print(x_np)\n",
    "\n",
    "# From another tensor\n",
    "x_ones = torch.ones_like(x_data) # retains the properties of x_data\n",
    "x_rand = torch.rand_like(x_data, dtype = torch.float) # overrides the datatype of x_data\n",
    "print(f\"\\nOnes Tensor: \\n{x_ones} \\nRandom Tensor: \\n{x_rand} \\n\")\n",
    "\n",
    "# With random or constant values:\n",
    "'''Shape is a tuple of tensor dimensions'''\n",
    "shape = (2,3,)\n",
    "rand_tensor = torch.rand(shape)\n",
    "ones_tensor = torch.ones(shape)\n",
    "zeros_tensor = torch.zeros(shape)\n",
    "print(f\"Random Tensor: \\n{rand_tensor} \\nOnes Tensor: \\n{ones_tensor} \\nZeros Tensor: \\n{zeros_tensor}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b162af19",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of tensor: torch.Size([3, 4])\n",
      "Datatype of tensor: torch.float32\n",
      "Device tensor is stored on:cpu\n"
     ]
    }
   ],
   "source": [
    "# ATTRIBUTES OF A TENSOR\n",
    "\n",
    "#Tensor attributes describe their shape, datatype, and the device on which they are stored\n",
    "tensor = torch.rand(3,4)\n",
    "print(f\"Shape of tensor: {tensor.shape}\\nDatatype of tensor: {tensor.dtype}\\nDevice tensor is stored on:{tensor.device}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b076065d",
   "metadata": {},
   "source": [
    "Over 100 tensor operations, including arithmetic, linear algerba, matrix manipalutaion(transposing, indexing, slicing), sampling and more can be found in __[here](https://pytorch.org/docs/stable/torch.html)__\n",
    "\n",
    "Each of these operations can be run on the GPU. By default, tensors are created on the CPU.\n",
    "We need to explicitly move tensors to the GPU using .to method(after checking GPU availability)\n",
    "We should keep in mind that copying large tensors across devices can be expensive in terms of time and memory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e2544f54",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First row: tensor([1., 1., 1., 1.])\n",
      "First column: tensor([1., 1., 1., 1.])\n",
      "Last column: tensor([1., 1., 1., 1.])\n",
      "tensor([[1., 0., 1., 1.],\n",
      "        [1., 0., 1., 1.],\n",
      "        [1., 0., 1., 1.],\n",
      "        [1., 0., 1., 1.]])\n",
      "\n",
      "tensor([[1., 0., 1., 1., 1., 0., 1., 1., 1., 0., 1., 1.],\n",
      "        [1., 0., 1., 1., 1., 0., 1., 1., 1., 0., 1., 1.],\n",
      "        [1., 0., 1., 1., 1., 0., 1., 1., 1., 0., 1., 1.],\n",
      "        [1., 0., 1., 1., 1., 0., 1., 1., 1., 0., 1., 1.]])\n",
      "\n",
      "z1 tensor([[1., 0., 1., 1.],\n",
      "        [1., 0., 1., 1.],\n",
      "        [1., 0., 1., 1.],\n",
      "        [1., 0., 1., 1.]]), \n",
      "z2 tensor([[1., 0., 1., 1.],\n",
      "        [1., 0., 1., 1.],\n",
      "        [1., 0., 1., 1.],\n",
      "        [1., 0., 1., 1.]])\n",
      "\n",
      "12.0 <class 'float'>\n",
      "tensor([[1., 0., 1., 1.],\n",
      "        [1., 0., 1., 1.],\n",
      "        [1., 0., 1., 1.],\n",
      "        [1., 0., 1., 1.]])\n",
      "\n",
      "tensor([[6., 5., 6., 6.],\n",
      "        [6., 5., 6., 6.],\n",
      "        [6., 5., 6., 6.],\n",
      "        [6., 5., 6., 6.]])\n"
     ]
    }
   ],
   "source": [
    "# OPERATIONS ON TENSORS\n",
    "\n",
    "# We move our tensor to the GPU if available\n",
    "if torch.cuda.is_available():\n",
    "    tensor = tensor.to(\"cuda\")\n",
    "\n",
    "# Standard numpy-like indexing and slicing:\n",
    "tensor = torch.ones(4,4)\n",
    "print(f\"First row: {tensor[0]}\")\n",
    "print(f\"First column: {tensor[:, 0]}\")\n",
    "print(f\"Last column: {tensor[..., -1]}\")\n",
    "\n",
    "tensor[:,1] = 0\n",
    "print(tensor)\n",
    "\n",
    "# Joining tensors with torch.cat to concatenate a sequence of tensors along a given dimension. torch.stack can also be used to join tensors that's subtly different from torch.cat\n",
    "t1 = torch.cat([tensor, tensor, tensor], dim=1)\n",
    "print(f\"\\n{t1}\\n\")\n",
    "\n",
    "# Arithmetic operations\n",
    "# This computes the matrix multiplication between two tensors. y1,y2,y3 will have the same value\n",
    "# ``tensor.T`` returns the transpose of a tensor\n",
    "\n",
    "# We calculate the matrix product of `tensor` and its transpose `tensor.T` using @, which is the equivalent to calling matmul()\n",
    "y1 = tensor @ tensor.T\n",
    "# same as the statement above, but we're calling matmul() directly instead of @ operator.\n",
    "y2 = tensor.matmul(tensor.T)\n",
    "# We create a random tensor of the same shape as the result of the matrix multiplication of `tensor` and `tensor.T`\n",
    "y3 = torch.rand_like(y1)\n",
    "# We performs the same matrix multiplication as the first two lines but specifies the output tensor `y3` for the result of the operation using the `out` parameter of the `matmul()`\n",
    "torch.matmul(tensor, tensor.T, out=y3)\n",
    "\n",
    "\n",
    "# This computes the element-wise product. z1, z2, z3 will have the same value\n",
    "z1 = tensor * tensor\n",
    "z2 = tensor.mul(tensor)\n",
    "print(f\"z1 {z1}, \\nz2 {z2}\\n\")\n",
    "z3 = torch.rand_like(tensor)\n",
    "torch.mul(tensor, tensor, out = z3)\n",
    "\n",
    "# Single-element tensors if you have a one-element tensor, like aggregating all values of a tensor into one value, you can convert it to a Python numerical value using item()\n",
    "# We calculate the sum of all the element in `tensor` using sum() method, assigned to `agg` \n",
    "agg = tensor.sum()\n",
    "# we extract the value of the sum, which convert the sum tensor to a Python scalar value.\n",
    "agg_item = agg.item()\n",
    "print(agg_item, type(agg_item))\n",
    "\n",
    "# In-place operations operations that store the result into the operand are called in-place. denoted by a _ suffix\n",
    "# for example: x.copy_(y), x.t_(), will change x\n",
    "print(f\"{tensor}\\n\")\n",
    "tensor.add_(5)\n",
    "print(tensor)\n",
    "''' \n",
    "In-place operations save some memory, but can be problematic when computing derivatives because of an immediate loss of history.\n",
    "Hence, their use is discouraged\n",
    "'''\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "8bcd159a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "t: tensor([1., 1., 1., 1., 1.])\n",
      "n: [1. 1. 1. 1. 1.]\n",
      "t: tensor([2., 2., 2., 2., 2.])\n",
      "n: [2. 2. 2. 2. 2.]\n",
      "t: tensor([2., 2., 2., 2., 2.], dtype=torch.float64)\n",
      "n: [2. 2. 2. 2. 2.]\n"
     ]
    }
   ],
   "source": [
    "#BRIDGE WITH NumPy\n",
    "#Tensors on the CPU and NumPy arrays can share their underlying memory locations, and changing one will change the other\n",
    "\n",
    "# Tensor to NumPy array\n",
    "t = torch.ones(5)\n",
    "print(f\"t: {t}\")\n",
    "n = t.numpy()\n",
    "print(f\"n: {n}\")\n",
    "# A change in the tensor reflects in the NumPy array\n",
    "t.add_(1)\n",
    "print(f\"t: {t}\")\n",
    "print(f\"n: {n}\")\n",
    "\n",
    "# NumPy array to Tensor\n",
    "n = np.ones(5)\n",
    "t = torch.from_numpy(n)\n",
    "# Changes in the NumPy array reflects in the tensor\n",
    "np.add(n, 1, out=n)\n",
    "print(f\"t: {t}\")\n",
    "print(f\"n: {n}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
